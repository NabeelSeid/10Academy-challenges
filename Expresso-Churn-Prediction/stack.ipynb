{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import xgboost as xgb\n",
    "import catboost as cat_\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class func() :   \n",
    "    def __init__(self, train, label, test, model, model_type, random_state):\n",
    "        self.train, self.label, self.test = train, label, test\n",
    "        self.model, self.model_type = model, model_type\n",
    "        self.random_state = random_state\n",
    "        \n",
    "        assert self.model_type in ('catboost', 'xgboost', 'lgbm'), 'Incorrect model_type'\n",
    "    def __call__(self, plot = True):\n",
    "        return self.fit(plot)\n",
    "\n",
    "    def fit(self, plot):\n",
    "        def catboost_fit(X_train, X_test, y_train, y_test):\n",
    "            self.model.fit(X_train,y_train,eval_set=[(X_test,y_test)],early_stopping_rounds=500,\n",
    "                           verbose=50,use_best_model=True)\n",
    "            x_test_predict = self.model.predict_proba(X_test)[:,1]\n",
    "            x_train_predict = self.model.predict_proba(X_train)[:,1]\n",
    "            self.val_p[test_index] = x_test_predict\n",
    "            self.test_p += self.model.predict_proba(self.test)[:,1]\n",
    "            return x_test_predict, x_train_predict\n",
    "\n",
    "        def xgboost_fit(X_train, X_test, y_train, y_test):\n",
    "            self.model.fit(X_train, y_train, early_stopping_rounds = 30, eval_metric=\"auc\",\n",
    "                           eval_set=[(X_test, y_test)], verbose = True)\n",
    "            x_test_predict = self.model.predict_proba(X_test, ntree_limit = self.model.get_booster().best_ntree_limit)[:,1]\n",
    "            x_train_predict = self.model.predict_proba(X_train, ntree_limit = self.model.get_booster().best_ntree_limit)[:,1]\n",
    "            self.val_p[test_index] = x_test_predict\n",
    "            self.test_p += self.model.predict_proba(self.test, ntree_limit = self.model.get_booster().best_ntree_limit)[:,1]\n",
    "            return x_test_predict, x_train_predict\n",
    "\n",
    "        def lgbm_fit(X_train, X_test, y_train, y_test):\n",
    "            self.model.fit(X_train, y_train, early_stopping_rounds = 30, eval_metric=\"auc\",\n",
    "                           eval_set=[(X_test, y_test)], verbose = True)\n",
    "            x_test_predict = self.model.predict_proba(X_test, num_iteration = self.model.best_iteration_)[:,1]\n",
    "            x_train_predict = self.model.predict_proba(X_train, num_iteration = self.model.best_iteration_)[:,1]\n",
    "            self.val_p[test_index] = x_test_predict\n",
    "            self.test_p += self.model.predict_proba(self.test, num_iteration = self.model.best_iteration_)[:,1]\n",
    "            return x_test_predict, x_train_predict\n",
    "\n",
    "\n",
    "        self.val_p = np.zeros(self.train.shape[0])\n",
    "        mean_val = []\n",
    "        mean_train = []\n",
    "        self.test_p = np.zeros(self.test.shape[0])\n",
    "        splits = 5\n",
    "        kf = StratifiedKFold(n_splits = splits)\n",
    "        for fold_count, (train_index, test_index) in enumerate(kf.split(self.train, self.label)):\n",
    "            X_train,X_test = self.train.iloc[train_index],self.train.iloc[test_index]\n",
    "            y_train,y_test = self.label.iloc[train_index],self.label.iloc[test_index]\n",
    "\n",
    "            print(f\"================================Fold{fold_count+1}====================================\")\n",
    "            if self.model_type == 'catboost': x_test_predict, x_train_predict = catboost_fit(X_train, X_test, y_train, y_test)\n",
    "            elif self.model_type == 'xgboost': x_test_predict, x_train_predict = xgboost_fit(X_train, X_test, y_train, y_test)\n",
    "            elif self.model_type == 'lgbm': x_test_predict, x_train_predict = lgbm_fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "            print('\\nValidation scores', roc_auc_score(y_test, x_test_predict), log_loss(y_test, x_test_predict))\n",
    "            print('Training scores', roc_auc_score(y_train, x_train_predict), log_loss(y_train, x_train_predict))\n",
    "            mean_val.append(roc_auc_score(y_test, x_test_predict))\n",
    "            mean_train.append(roc_auc_score(y_train, x_train_predict))\n",
    "\n",
    "        if plot:\n",
    "            feat_imp = pd.DataFrame(sorted(zip(self.model.feature_importances_,self.train.columns)), columns=['Value','Feature'])\n",
    "            plt.figure(figsize=(30,25))\n",
    "            sns.barplot(x=\"Value\", y=\"Feature\", data=feat_imp.sort_values(by=\"Value\", ascending=False))\n",
    "            plt.ylabel('Feature Importance Score')\n",
    "            plt.show()\n",
    "        print(np.mean(mean_val), np.mean(mean_train), np.std(mean_val))\n",
    "        return self.val_p, self.test_p/splits, self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('AIMS_Train.csv')\n",
    "data_test=  pd.read_csv('AIMS_Test.csv')\n",
    "submission = pd.read_csv('AIMS_SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.drop(['user_id', 'MRG',], 1, inplace = True)\n",
    "data_test.drop(['user_id', 'MRG',], 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_train.copy()\n",
    "test = data_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "data = pd.concat((train, test)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['REVENUE-MONTANT'] = data['REVENUE'] - data['MONTANT']\n",
    "data['REVENUE/MONTANT'] = data['REVENUE'] / data['MONTANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# TENURE: duration\n",
    "# values:'K > 24 month','I 18-21 month','H 15-18 month', 'G 12-15 month':12...\n",
    "# extract the lower bounder/the first integer\n",
    "extract_tenure = lambda str : int(re.search(r'\\d+', str).group())\n",
    "\n",
    "data['TENURE'] = data['TENURE'].apply(extract_tenure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TENURE averge, every tenure has a range of 3\n",
    "# add 3 to lower boundery and take the average\n",
    "tenure_avg = lambda t: (t+3)/2\n",
    "\n",
    "data['TENURE_avg'] = data['TENURE'].apply(tenure_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TENURE/FREQUENCE_RECH'] = data['TENURE_avg'] / data['FREQUENCE_RECH']\n",
    "data['TENURE/REGULARITY'] = data['TENURE_avg'] / data['REGULARITY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = data.groupby('REGION').mean()\n",
    "region.drop('CHURN', 1, inplace = True)\n",
    "cols = []\n",
    "\n",
    "for i in region.columns:\n",
    "    if i != 'REGION':\n",
    "        region[i+'_reg_mean_all'] = region[i]\n",
    "        region.drop(i, 1, inplace = True)\n",
    "        cols.append(i+'_reg_mean_all')\n",
    "\n",
    "data = pd.merge(data, region, on='REGION', how = 'left')\n",
    "for col in cols: data[col+'_freq'] = data[col].map(data[col].value_counts().to_dict())/len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['freq*montant'] = data['FREQUENCE'] * data['MONTANT']\n",
    "data['freq*rech'] = data['FREQUENCE'] * data['FREQUENCE_RECH']\n",
    "data['freq*revenue'] = data['FREQUENCE'] * data['REVENUE']\n",
    "data['freq*segment'] = data['FREQUENCE'] * data['ARPU_SEGMENT']\n",
    "\n",
    "data['freq/montant'] =  data['MONTANT']/ data['FREQUENCE']\n",
    "data['freq/rech'] = data['FREQUENCE'] / data['FREQUENCE_RECH']\n",
    "data['freq/revenue'] = data['FREQUENCE'] / data['REVENUE']\n",
    "data['freq/segment'] = data['FREQUENCE'] / data['ARPU_SEGMENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reg_log'] = np.log1p(data['REGULARITY'])\n",
    "data['rech_log'] = np.log1p(data['FREQUENCE_RECH'])\n",
    "data['data_log'] = np.log1p(data['DATA_VOLUME'])\n",
    "data['montant_log'] = np.log1p(data['MONTANT'])\n",
    "data['rev_log'] = np.log1p(data['REVENUE'])\n",
    "data['freq_log'] = np.log1p(data['FREQUENCE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['reglog-montlog'] = data['reg_log'] - data['montant_log']\n",
    "data['revlog/montlog'] = data['REVENUE'] / data['montant_log']\n",
    "data['tenure/rechlog'] = data['TENURE_avg'] / data['rech_log']\n",
    "data['reglog-datalog'] = data['reg_log'] - data['data_log']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['REGION', 'TOP_PACK']\n",
    "data.drop(drop, 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[:ntrain].copy()\n",
    "#train.drop_duplicates(inplace = True, ignore_index=True)\n",
    "target = train.CHURN.copy()\n",
    "train.drop('CHURN', axis=1, inplace=True)\n",
    "\n",
    "test = data[ntrain:].copy()\n",
    "test.drop('CHURN', axis=1, inplace=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL 1 - CATBOOST\n",
    "The CATBOOST and XGBOOST models were trained on GPU(Google Colab) in order to save time. To train on CPU, you would have to remove the task_type and devices parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost = cat_.CatBoostClassifier(n_estimators=10000, max_depth=6, eval_metric='AUC', reg_lambda = 370) #, task_type=\"GPU\", devices='0:1'\n",
    "\n",
    "func_= func(train, target, test, catboost, 'catboost', 1000)\n",
    "val_p1, test_p1, model1 = func_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
